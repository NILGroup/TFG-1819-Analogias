\chapter{Trabajo Realizado}
\label{cap:TrabajoRealizado}


En este capítulo se describe el trabajo realizado por cada uno de los autores de este proyecto.


\section{Trabajo realizado por Irene}
\label{cap:sec:trabajo_Irene}

Al comenzar el proyecto, la primera tarea a realizar consistió en investigar las bibliotecas que se podrían utilizar para el procesado de las palabras. Al principio se encontró una biblioteca para el procesado de texto en Python llamada \textit{NLTK}, pero se pudo comprobar que las etiquetas que asignaba a las palabras no eran del todo correctas. Se decidió buscar otra biblioteca distinta y se recurrió a Spacy. Con esta librería ya se pudo etiquetar correctamente todas las palabras, lo que dio lugar a un primer diseño de un programa utilizando Jupyter. A continuación, investigué qué tecnologías utilizar para la realización del prototipo tecnológico. Encontramos como entorno de desarrollo \textit{Pycharm} y como framework de desarrollo web \textit{Django}. 

Una vez seleccionadas estas tecnologías, se investigó cómo poder sacarles el mejor partido y comenzamos a desarrollar el primer el prototipo tecnológico.
En esta tarea, mi cometido principal fue conectar las vistas html con la lógica en Python. A continuación tuvimos que aprender cómo se implementa un formulario web y como se hacía una redirección a la vista. Una vez tuvimos claro cómo realizar esta tarea, integramos el código desarrollado inicialmente en Jupyter en nuestro servicio web, finalizando el prototipo tecnológico.

En cuanto a la memoria, dividimos su elaboración en dos partes iguales entre los dos miembros del grupo, intentando que ambos tuviésemos asignada una parte en todos los capítulos de la misma, por lo que ambos redactamos tanto una parte de la introducción (en la que me correspondió redactar la motivación) como el estado de la cuestión (en este caso me correspondió el apartado de Lectura Fácil y Procesamiento del Lenguaje Natural).

La investigación de como funcionaba ConceptNet y su API la hicimos conjuntamente. A partir de aquí se realizó un prototipo con esta red semántica que contenía dos servicios web uno para los sinónimos y otro para los términos relacionados. 

Por otro lado se obtuvieron ficheros con las 1.000, 5.000 y 10.000 palabras más usadas según la RAE, se hizo un filtrado de estas palabras para quedarnos solo con adjetivos, verbos y nombres utilizando SpaCy.

Tras la realización del prototipo y hacer las pruebas correspondientes nos dimos cuenta que los resultados obtenidos no eran válidos por lo que se buscó otra red semántica.

Se decidió probar con WordNet, inicialmente tuvimos muchos problemas para poder obtener los recursos, ya que no tienen una API, sino que es una base de datos que te debes descargar.


Con los recursos descargados, estudiamos como estaban estructurados para poder utilizarlos según nuestros intereses y nos pusimos a programar el prototipo.

Nos descargamos los ficheros de la base de datos e investigamos como funcionaban para poder utilizarlos. Yo empecé a diseñar la vista del prototipo. Y después, nos pusimos los dos con la parte del backend.
La implementación de todos los servicios web se realizó conjuntamente entre mi compañero y yo.


Después, ya empezamos a trabajar en lo que sería el proyecto propiamente dicho, empezando por diseñar la vista. Para ello realizamos una iteración competitiva tanto Pablo como yo, para ver con que diseño nos quedábamos finalmente.

Se decidió que mi diseño de la vista era el que se va a implementar, añadiendo algunos aspectos que había añadido Pablo en su diseño. Por lo que adapté mi vista añadiendo dichos cambios para utilizarla en el proyecto que se desarrollaría finalmente.

A continuación, desarrollé la parte de la lógica de la vista de la aplicación, ya que aparte de la lógica de negocio desarrollada en Python, para mostrar los datos correctamente utilizamos jQuery con peticiones ajax para tratar los datos. Esta parte me llevó varios días ya que se presentaron varias dificultades.

Al terminar esta tarea, nos reunimos Pablo y yo para desplegar el proyecto en el contenedor que nos proporcionó el grupo NIL de la facultad de informática. 

Cuando subimos el proyecto al contenedor, nos dimos cuenta de que  había varios problemas, por lo que estuvimos varios días solucionándolos para que funcionase correctamente de cara a la evaluación que teníamos por delante en pocos días.

Para la evaluación de la aplicación, creamos entre Pablo y yo un formulario de Google Forms. Y una vez realizada, se transcribió a la memoria también entre los dos.

En todo momento, a la vez que se realizaba la implementación de código (ya sea backend o fronted) se iba realizando la memoria. Siempre dividida a partes iguales entre mi compañero y yo. 


\section{Trabajo realizado por Pablo}
\label{cap:sec:trabajo_Pablo}

Al igual que mi compañera, lo primero que hicimos fue investigar como podíamos etiquetar las palabras, encontramos la librería NLTK de Python para hacerlo, pero tras un primer intento nos dimos cuenta de que muchas palabras no estaban etiquetadas como deberían por lo que decidimos buscar alternativas, indagando un poco encontramos Spacy, la probamos y obtuvimos unos resultados mucho mejores que con NLTK por lo que decidimos utilizar esta última (todo esto lo hicimos desde el Jupyter). 

Cuando terminamos de etiquetar las palabras nos pusimos a investigar herramientas para el desarrollo del prototipo tecnológico y nos decantamos por utilizar Django como framework integrado en Pycharm, que es el entorno de desarrollo.

A continuación empezamos el desarrollo del prototipo tecnológico primero investigando como se utilizaban estas tecnologías(implementar formularios, hacer las redirecciones a vista...). Para finalizar migramos lo hecho desde Jupyter a nuestro servicio web.

Irene y yo nos dividimos la redacción de la memoria de tal manera que los dos hicimos tanto la parte de la introducción como del estado de la cuestión, de la introducción a mí me tocó la parte de los objetivos y del estado de la cuestión la parte de figuras retóricas y servicios web.

La investigación de como funcionaba ConceptNet y su API la hicimos de manera conjunta.

Tras investigar el funcionamiento de esta red semántica, empezamos a implementar un prototipo para probar si es funcional.

Mientras estábamos trabajando en esto, avanzamos en la redacción de la memoria, dividiéndonos el trabajo equitativamente.

Cuando terminamos la implementación del prototipo, se lo presentamos a los directores del TFG y nos dimos cuenta de que no iba a ser útil por lo que empezamos a trabajar en otra red semántica: WordNet.

Investigamos como funcionaba esta red semántica, estuvimos varios días con esto, hasta que descubrimos para acceder a los datos no hay una API pública sino que es una base de datos que hay que descargarse.

Encontramos varios sitios que hacían uso de la misma y para poder descargarse los recursos había que registrarse. Me registré en varios de ellos pero no nos servían ya que no estaban en castellano. Finalmente tras varios días encontramos los recursos necesarios en la página web de la universidad de Princeton.

Con los recursos descargados, estudiamos como estaban estructurados para poder utilizarlos según nuestros intereses y nos pusimos a programar el prototipo.

Mientras Irene empezaba a diseñar la vista, yo empecé a desarrollar la lógica interna para integrarla con los recursos descargados.

Después nos pusimos los dos con la parte de la lógica del prototipo para terminarlo cuanto antes.

A continuación, empecé a diseñar una prueba estadística para comprobar de manera empírica que red semántica ofrece mejores resultados. Realicé la prueba y la puse en común con Irene para analizar los resultados obtenidos.

Con los resultados de las pruebas y tras enseñar a los directores del TFG los resultados que ofrecía, decidimos que con estos recursos se desarrollaría la aplicación. 

Empezamos a realizar la aplicación final. Me puse a trabajar en mi prototipo visual para la iteración competitiva con Irene para ver como sería el diseño visual.

A continuación, empecé a desarrollar la base de datos de pictogramas para integrarlos en nuestra aplicación. Me descargué los pictogramas e implementé un script que relacionaba los pictogramas descargados con los recursos de WordNet, utilizando la API pública de ARASAAC, que relacionaba sus pictogramas con los recursos de WordNet mediante el offset. Sin embargo, estos offset correspondían a una versión de WordNet que no era la que estábamos utilizando, por lo que tuve que utilizar una API de la universidad de Princeton para traducir dichos offset a los que utiliza la versión que trabajamos nosotros, que es la 3.0.

Cuando acabé la base de datos de pictogramas, Irene y yo subimos la aplicación que teníamos implementada en local al servidor ofrecido por el grupo NIL de la facultad de informática para que pudiese estar disponible para todo el mundo. 

Cuando subimos el proyecto, nos dimos cuenta de que en el servidor había varios problemas, por lo que estuvimos varios días solucionándolos para que funcionase correctamente de cara a la evaluación que teníamos por delante en pocos días.


Una vez subido y con los errores corregidos, seguimos avanzando en el desarrollo de la memoria y comenzamos a diseñar un formulario para realizar la evaluación de la aplicación con usuarios finales terminando el desarrollo del proyecto.




